{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2-Aprendizaje de Máquinas Probabilítico\n",
    "* Profesor: Felipe tobar\n",
    "* Aux: Alejandro Cuevas y Alejandro Veragua\n",
    "\n",
    "* Preguntas: Ucursos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte a: Support vector machines\n",
    "## Descripción:\n",
    "* Implementar un algoritmo `support vector machine` para clasificación usando `sklearn`.\n",
    "* La tarea se dividirá en 2 partes:\n",
    "    * Tutorial `SVM` con `sklearn`, implementar kernels gaussianos.\n",
    "    * Diseñar un clasificador multiclase para la base de datos de MNIST usando kernel gaussiano en adición con un kernel extra implementado a su elección.\n",
    "* Entregue este mismo notebook de `Python` con sus desarrollos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 1: SVM y sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos ( igual que P3 - Tarea 1, Otoño 2017)\n",
    "Cargamos los datos del archivo 'datosT1P3.txt' de la P3 de la tarea pasada, donde se trata de un problema de clasificación binaria (clases 0, 1) de 2 dimensiones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#carga de datos\n",
    "data = np.genfromtxt('datosT1P3.txt',delimiter=',')\n",
    "X = data[:2, :]\n",
    "Y = data[2, :].astype(int)\n",
    "print('Dimension de los datos de entrada: ', X.shape)\n",
    "print('Dimension de etiquetas: ', Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Separe los los datos en 2 conjuntos:\n",
    "    * conjunto de entrenamiento (70%).\n",
    "    * conjunto de prueba (30%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#división de los conjuntos de entrenamiento y prueba\n",
    "X_train =\n",
    "X_test = \n",
    "y_train = \n",
    "y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Grafique los datos con su respectiva etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funcion para visualizar la region de clasificación para el caso bidimensional\n",
    "def plot_region(X, Y, classifier, title='Region de clasificacion de SVM'):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    h = np.abs(x_max / x_min)/20\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=plt.cm.Paired)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funcion para visualizar y graficar la matriz de confusion \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.round(cm, decimals=3)\n",
    "\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines y Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las support vector machines resuelven el siguiente problema de optimización:\n",
    "\n",
    "$\\hspace{1.4cm}  \\min_{\\texttt{w}, b, \\xi}{\\frac{1}{2}\\texttt{w}^\\texttt{T}\\texttt{w}} + C \\sum_{i=1}^n \\xi_i$\n",
    "\n",
    "\n",
    "s.a. $\\hspace{1cm} y_n(\\texttt{w}^\\texttt{T}\\phi(x_i) + b) \\geq 1-\\xi_i \\hspace{1cm} n=1,2,...,N$\n",
    "\n",
    "\n",
    "$\\hspace{1.8cm} \\texttt{w} \\in \\mathbb{R}^d \\hspace{0.5cm} b \\in \\mathbb{R}$\n",
    "\n",
    "Para ello se utilizará la librería `sklearn` la cual provee una implementación de `SVM` para clasificación. Por ejemplo, para configurar `SVM` con los datos anterior junto a un kernel polinomial, primero se define el kernel de la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel polinomial\n",
    "Un kernel polinomial de grado $d$ queda definido como:\n",
    "$$\\mathbf{K}(X,Y) = (x \\cdot y + c)^d$$\n",
    "\n",
    "Donde el método recibirá la matriz de Gram evaluada con el kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polynomial_kernel(x, y, degree=2, coef=0.1):\n",
    "    k = np.dot(x, y)\n",
    "    k += coef\n",
    "    k **= degree\n",
    "    return k\n",
    "\n",
    "def gram_matrix_poly(X, Y):\n",
    "    G = np.zeros((X.shape[0], Y.shape[0]))\n",
    "    for i, x in enumerate(X):\n",
    "        for j, y in enumerate(Y):\n",
    "            G[i,j] = polinomial_kernel(x, y, degree, bias)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Luego el `SVM` se invoca de la forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "degree, bias = 3, 1  # parametros del kernel\n",
    "clf = svm.SVC(kernel=gram_matrix_poly,  C=1)  # crea el clasificador\n",
    "clf.fit(X_train, y_train) # entrena \n",
    "print('Support vectors por clase: ' ,clf.n_support_)\n",
    "Y_pred = clf.predict(X_test)  # clasifica\n",
    "\n",
    "print (\"Accuracy on test set: \" , accuracy_score(y_test, Y_pred, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimente con disintos parámetros del kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grafico la region de clasificación para el SVM entrenado\n",
    "plot_region(X_train, y_train, clf, 'Region de clasificacion kernel polinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grafica la matriz de confusión\n",
    "cm = confusion_matrix(y_test, Y_pred)\n",
    "classes_name = ['0', '1']\n",
    "plot_confusion_matrix(cm, classes_name , normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Kernel RBF (gaussiano)\n",
    "El kernel gaussiano se define de la forma y tiene un único parámetro que denotamos $\\gamma$:\n",
    "$$\\mathbf{K}(x,y) = \\exp \\big{(}-\\gamma{\\lVert x-y \\rVert^2} \\big{)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Actividad 2:\n",
    "* Implemente el kernel gaussiano y clasifique los datos de tarea 1 pregunta 3.\n",
    "* Comente sobre la variación del parámetro $\\gamma$, ¿Qué pasa para disintos valores de este?, ¿Qué interpretación tiene?\n",
    "* Grafique la región de clasificación para este caso ¿Cómo cambia con respecto al caso polinomial?\n",
    "\n",
    "Para esto, le puede ser útil la [documentación del método](http://scikit-learn.org/stable/modules/svm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(u, v, gamma):\n",
    "    \n",
    "    \n",
    "def gram_matrix_gaussian(X, Y):\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "print (\"Accuracy on test set: \" , accuracy_score(y_test, Y_pred, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_region(X_train, y_train, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM y MNIST\n",
    "\n",
    "Para esta parte de la tarea se trabajará con el set de datos [MNIST](http://yann.lecun.com/exdb/mnist/), el cual contiene datos de escritura para dígitos del 1 al 10, donde cada imagen de `28x28` es representada por un vector fila de dimensión 784.\n",
    "\n",
    "Su primera tarea será descargar este set de datos y visualizarlos. Para facilitar la lectura de la base de datos se recomienda descargar un parser de MNIST, por ejemplo [este](https://github.com/sorki/python-mnist). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preámbulo: Descargar e importar base de datos\n",
    "\n",
    "Descargue los siguientes archivos de la página de MNIST:\n",
    " * `train-images-idx3-ubyte.gz`\n",
    " * `train-labels-idx1-ubyte.gz`\n",
    " * `t10k-images-idx3-ubyte.gz`\n",
    " * `t10k-labels-idx1-ubyte.gz`\n",
    " \n",
    "Estos archivos contienen conjuntos de entrenamiento y prueba que serán utilizados por su algoritmo. Si descargó el parser recomendado en el paso anterior, la carga de datos en python es de la siguiente forma (asumiendo que los archivos descomprimidos están en la carpeta `/MNIST_data`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "mndata = MNIST('MNIST_data')\n",
    "train_images, train_labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la carga de datos fue correcta, se podrán visualizar las imágenes, para esto, primero se debe pasar a formato `numpy array`, y luego para cada imagen que se quiera mostrar pasar el vector fila a una matriz de `28x28`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convertir datos al formato de numpy\n",
    "X1_train = np.array(train_images)\n",
    "y1_train = np.array(train_labels)\n",
    "X1_test = np.array(test_images)\n",
    "y1_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mostrar primeras 24 imágenes de entrenamiento\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(24):\n",
    "    plt.subplot(3,8,i+1)\n",
    "    plt.imshow(X1_train[i].reshape((28,28)), cmap='gray')\n",
    "    plt.title('label: ' + str(y1_train[i]))\n",
    "    plt.gca().axes.get_xaxis().set_visible(False) # borrar eje x\n",
    "    plt.gca().axes.get_yaxis().set_visible(False) # borrar eje y\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Dimensión de vectores de características: %d\" % (np.shape(X1_train)[1]) )# 784\n",
    "print (\"Nº de imágenes de entrenamiento: %d\" % (len(X1_train)) ) # 60000\n",
    "print (\"Nº de imágenes de prueba: %d\" % (len(X1_test)) ) # 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 3:\n",
    "* Implemente un clasificador multiclase para la base de datos `MNIST` usando `SVM` y muestre su matriz de confusión.\n",
    "* Comente sobre su estrategia para el problema multiclase ¿Como el `SVM` separá en múltiples clases?.\n",
    "* Implemente un kernel a elección adicional fundamentando su desición y comparé resultados ¿Cómo afectan los parámetros de su nuevo kernel?.\n",
    "\n",
    "Puede notar que para este caso de cada muestra es de dimensión 784, por lo que podría plantear un método de reducción de dimensionalidad, u obtener características por sobre las imágenes. Se recomienda usar principal component analysis.\n",
    "\n",
    "Una pagina con sugerencia de kernels [aqui](http://crsouza.com/2010/03/17/kernel-functions-for-machine-learning-applications/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Accuracy on test set: \" , accuracy_score(y_test, Y_pred, normalize=True))\n",
    "\n",
    "cm = confusion_matrix(y1_test, Y1_pred)\n",
    "classes_name = ['0', '1', '2', '3', '4', '5', '6','7', '8', '9']\n",
    "plot_confusion_matrix(cm, classes_name , normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
